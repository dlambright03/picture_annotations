# ADA Annotator - Image Accessibility Automation

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)

Automatically generate ADA-compliant alt-text descriptions for images in documents using AI-powered analysis through Microsoft Semantic Kernel.

## ğŸ¯ Purpose

Help college professors and educators make their educational documents ADA-compliant by automatically generating descriptive alternative text for images embedded in Word documents, PDFs, and PowerPoint presentations.

## âœ¨ Features (Phase 1 Complete)

- ğŸ“„ **DOCX & PPTX Processing**: Extract images from Microsoft Word and PowerPoint files
- ğŸ¤– **AI-Powered Alt-Text**: Generate ADA-compliant descriptions using GPT-4o Vision
- ğŸ”„ **Semantic Kernel Integration**: Robust AI orchestration with retry logic and error handling
- ğŸ“Š **Context-Aware Generation**: 5-level hierarchical context extraction for accurate descriptions
- âœ… **ADA Compliance Validation**: Automatic validation of length, content, and formatting
- ğŸ¯ **Position Preservation**: Images remain in exact original positions
- ï¿½ **Comprehensive Reporting**: Markdown reports with statistics, costs, and error tracking
- âš¡ **Batch Processing**: Process multiple images with progress tracking
- ğŸ›¡ï¸ **Error Resilience**: Continue processing on individual failures
- ğŸ“ **Structured Logging**: JSON logs with correlation IDs for debugging

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11 or higher
- [uv](https://github.com/astral-sh/uv) - Fast Python package manager
- Azure OpenAI account with GPT-4o deployment

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/yourusername/ada-annotator.git
cd ada-annotator
```

2. **Run automated setup** (recommended):
```powershell
# Windows PowerShell
.\scripts\setup.ps1
```

This script will:
- Install uv if not already installed
- Create virtual environment
- Install all dependencies
- Create `.env` file from template
- Verify installation

3. **Configure Azure OpenAI** (edit `.env`):
```bash
AI_SERVICE_TYPE=azure_openai
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

4. **Process your first document:**
```bash
# Using uv with the annotate command (simplest)
uv run annotate --input tests/fixtures/documents/sample.docx --output output.docx --log-level INFO

# Or using the full module path
uv run python -m ada_annotator.cli \
    --input tests/fixtures/documents/sample.docx \
    --output output.docx \
    --log-level INFO

# Or activate virtual environment first, then use the command directly
# Windows
.\.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate

annotate --input tests/fixtures/documents/sample.docx --output output.docx --log-level INFO
```

See [SETUP_GUIDE.md](SETUP_GUIDE.md) for detailed setup instructions and troubleshooting.

## ğŸ“– Usage

### Command Line Interface (CLI)

The primary interface for Phase 1 is the command-line tool:

```bash
# Basic usage - process a DOCX file (using uv)
uv run annotate --input document.docx --output annotated.docx

# Process a PowerPoint presentation
uv run annotate --input presentation.pptx --output annotated.pptx

# Use external context file for better descriptions
uv run annotate \
    --input document.docx \
    --output annotated.docx \
    --context course_syllabus.txt

# Dry-run mode (extract images and preview without generating alt-text)
uv run annotate --input document.docx --dry-run

# Limit processing to first 5 images (for testing)
uv run annotate \
    --input document.docx \
    --output annotated.docx \
    --max-images 5

# Enable verbose logging
uv run annotate \
    --input document.docx \
    --output annotated.docx \
    --log-level DEBUG
```

**Note:** `uv run annotate` automatically uses the project's virtual environment. You can also activate the virtual environment and use `annotate` directly.

### Common Workflows

**1. Quick Test with Sample Document:**
```bash
# Process sample document with debug logging
uv run annotate \
    --input tests/fixtures/documents/sample.docx \
    --output output/annotated.docx \
    --log-level DEBUG
```

**2. Batch Processing Multiple Documents:**
```bash
# Process all DOCX files in a directory (using PowerShell)
Get-ChildItem *.docx | ForEach-Object {
    uv run annotate --input $_.Name --output "output/$($_.Name)"
}
```

**3. Educational Content with Context:**
```bash
# Include course context for better descriptions
uv run annotate \
    --input lecture_notes.docx \
    --output annotated_lecture.docx \
    --context course_context.md \
    --log-level INFO
```

### Output Files

After processing, you'll get:

- **Annotated Document**: Your original document with AI-generated alt-text applied
- **Markdown Report**: `{output_name}_report.md` with:
  - Processing statistics (success rate, duration)
  - List of processed images with alt-text previews
  - Failed images with error messages
  - Token usage and estimated costs
- **JSON Log File**: `logs/ada-annotator.log` with structured processing logs

### Streamlit Web Interface (Future)

A web interface is planned for Phase 2:

1. **Upload Document**: Drag and drop a DOCX file or click to browse
2. **Extract Images**: System automatically extracts all images
3. **Generate Alt-Text**: AI analyzes each image and creates descriptions
4. **Review**: Preview generated alt-text for each image
5. **Download**: Get your annotated document with alt-text applied

## ğŸ—ï¸ Project Structure

```
ada-annotator/
â”œâ”€â”€ src/ada_annotator/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Pydantic settings and configuration
â”‚   â”œâ”€â”€ exceptions.py          # Custom exception hierarchy
â”‚   â”œâ”€â”€ cli.py                 # Command-line interface (Phase 1)
â”‚   â”œâ”€â”€ app.py                 # Streamlit web app (Phase 2 - planned)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ image_metadata.py  # Image extraction results
â”‚   â”‚   â”œâ”€â”€ context_data.py    # Hierarchical context
â”‚   â”‚   â”œâ”€â”€ alt_text_result.py # AI generation results
â”‚   â”‚   â””â”€â”€ processing_result.py # Document processing summary
â”‚   â”‚
â”‚   â”œâ”€â”€ document_processors/   # DOCX & PPTX handling
â”‚   â”‚   â”œâ”€â”€ base_extractor.py  # Abstract extractor base
â”‚   â”‚   â”œâ”€â”€ docx_extractor.py  # DOCX image extraction
â”‚   â”‚   â”œâ”€â”€ pptx_extractor.py  # PPTX image extraction
â”‚   â”‚   â”œâ”€â”€ base_assembler.py  # Abstract assembler base
â”‚   â”‚   â”œâ”€â”€ docx_assembler.py  # DOCX alt-text application
â”‚   â”‚   â””â”€â”€ pptx_assembler.py  # PPTX alt-text application
â”‚   â”‚
â”‚   â”œâ”€â”€ ai_services/           # AI integration
â”‚   â”‚   â””â”€â”€ semantic_kernel_service.py # SK + Azure OpenAI
â”‚   â”‚
â”‚   â”œâ”€â”€ generators/            # Alt-text generation
â”‚   â”‚   â””â”€â”€ alt_text_generator.py # Orchestrator with validation
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Utility modules
â”‚       â”œâ”€â”€ logging.py         # Structured logging (structlog)
â”‚       â”œâ”€â”€ error_handler.py   # Error handling framework
â”‚       â”œâ”€â”€ error_tracker.py   # Error tracking and categorization
â”‚       â”œâ”€â”€ context_extractor.py # 5-level context extraction
â”‚       â”œâ”€â”€ image_utils.py     # Image processing utilities
â”‚       â”œâ”€â”€ retry_handler.py   # Exponential backoff retry logic
â”‚       â””â”€â”€ report_generator.py # Markdown report generation
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                  # Unit tests (271 tests, 100% pass)
â”‚   â”œâ”€â”€ integration/           # Integration tests (planned)
â”‚   â””â”€â”€ fixtures/              # Test documents and data
â”‚       â”œâ”€â”€ documents/         # Sample DOCX/PPTX files
â”‚       â””â”€â”€ context/           # Sample context files
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ requirements.md        # Project requirements
â”‚   â”œâ”€â”€ phase_summaries/       # Phase implementation summaries
â”‚   â””â”€â”€ adr/                   # Architecture Decision Records
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup.ps1              # Automated setup script (Windows)
â”‚
â”œâ”€â”€ .copilot-tracking/         # Implementation tracking (internal)
â”‚   â”œâ”€â”€ plans/                 # Task plans and checklists
â”‚   â”œâ”€â”€ details/               # Detailed specifications
â”‚   â”œâ”€â”€ research/              # Research and references
â”‚   â””â”€â”€ changes/               # Implementation change logs
â”‚
â”œâ”€â”€ pyproject.toml             # Project config (dependencies, tools)
â”œâ”€â”€ .env.example               # Environment variable template
â”œâ”€â”€ SETUP_GUIDE.md             # Detailed setup instructions
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Development

### Running Tests

```bash
# Run all tests with coverage report
pytest --cov=src/ada_annotator --cov-report=term-missing

# Run specific test file
pytest tests/unit/test_alt_text_generator.py -v

# Run tests for a specific module
pytest tests/unit/test_docx_extractor.py tests/unit/test_pptx_extractor.py -v

# Generate HTML coverage report
pytest --cov=src/ada_annotator --cov-report=html
# Open htmlcov/index.html in browser

# Run with verbose output and show print statements
pytest -v -s

# Run only failed tests from last run
pytest --lf
```

**Current Test Status:**
- **271 tests passing (100%)**
- **87% code coverage** (exceeds 80% target)
- All modules tested (unit tests)
- Integration tests planned for Phase 2

### Code Quality

```bash
# Format code with black (79-char line limit)
black src/ tests/ --line-length 79

# Lint with ruff
ruff check src/ tests/

# Fix auto-fixable issues
ruff check src/ tests/ --fix

# Type check with mypy
mypy src/ada_annotator

# Run all quality checks
black src/ tests/ --line-length 79 --check
ruff check src/ tests/
mypy src/ada_annotator
pytest --cov=src/ada_annotator --cov-fail-under=80
```

### Project Standards

All code follows:
- **PEP 8**: Python style guide
- **PEP 257**: Docstring conventions
- **Type hints**: On all function signatures
- **79-character line limit**: For readability
- **4-space indentation**: Standard Python
- **Comprehensive error handling**: All edge cases covered
- **Structured logging**: JSON logs with correlation IDs

See [.github/instructions/python.instructions.md](.github/instructions/python.instructions.md) for full coding standards.

### Using UV Commands

```bash
# Install dependencies
uv pip install -e ".[dev]"

# Add a new package
uv pip install package-name

# Update all dependencies
uv pip install --upgrade -e ".[dev]"

# Sync dependencies from pyproject.toml
uv pip sync
```

## ğŸ“‹ Requirements

See [docs/requirements.md](docs/requirements.md) for detailed project requirements.

### Core Dependencies

- **Document Processing**: python-docx, pypdf, python-pptx, Pillow
- **AI/ML**: semantic-kernel, openai, azure-identity
- **Web Framework**: streamlit
- **Configuration**: python-dotenv, pydantic

## ğŸ—ºï¸ Roadmap

### Phase 1: CLI Implementation âœ… COMPLETE
- [x] Project infrastructure (logging, models, error handling)
- [x] CLI argument parsing and validation
- [x] DOCX image extraction with position metadata
- [x] PPTX image extraction with EMU precision
- [x] 5-level hierarchical context extraction
- [x] Semantic Kernel + Azure OpenAI integration
- [x] Alt-text generation with validation
- [x] DOCX output with position preservation
- [x] PPTX output with property preservation
- [x] Markdown reports and error tracking
- [x] Comprehensive test suite (87% coverage)
- [x] Complete documentation

**Status:** Phase 1 is production-ready with >80% test coverage

### Phase 2: Web Interface (Planned - Week 3-4)
- [ ] Streamlit web application
- [ ] File upload interface
- [ ] Real-time processing progress
- [ ] Manual alt-text review/editing
- [ ] Batch document processing
- [ ] Deploy to Azure App Service

### Phase 3: Enhanced Features (Future)
- [ ] PDF support with OCR integration
- [ ] Multi-language support
- [ ] Custom validation rules
- [ ] Alt-text quality scoring
- [ ] A/B testing for prompt optimization
- [ ] Integration with LMS platforms

### Phase 4: Enterprise Features (Future)
- [ ] Azure Functions deployment
- [ ] Queue-based batch processing
- [ ] User authentication and authorization
- [ ] Document version history
- [ ] Audit logging and compliance reporting
- [ ] RESTful API for integrations

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Microsoft Semantic Kernel team for the excellent AI orchestration framework
- OpenAI/Azure OpenAI for powerful vision capabilities
- python-docx, python-pptx, pypdf maintainers for document processing libraries

## ğŸ“ Support

- ğŸ“§ Email: your.email@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/ada-annotator/issues)
- ğŸ“– Documentation: [Project Docs](https://github.com/yourusername/ada-annotator/docs)

## ğŸ”’ Security

- Never commit `.env` files
- Store API keys securely in environment variables
- Use Azure Key Vault for production deployments
- Follow FERPA guidelines for educational records

---

**Made with â¤ï¸ for accessibility in education**
