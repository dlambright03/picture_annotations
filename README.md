# ADA Annotator - Image Accessibility Automation

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)

Automatically generate ADA-compliant alt-text descriptions for images in documents using AI-powered analysis through Microsoft Semantic Kernel.

## ğŸ¯ Purpose

Help college professors and educators make their educational documents ADA-compliant by automatically generating descriptive alternative text for images embedded in Word documents, PDFs, and PowerPoint presentations.

## âœ¨ Features (Phase 1 Complete)

- ğŸ“„ **DOCX & PPTX Processing**: Extract images from Microsoft Word and PowerPoint files
- ğŸ“‹ **PDF Support**: Extract images from PDFs (debug/extract mode only)
- ğŸ¤– **AI-Powered Alt-Text**: Generate ADA-compliant descriptions using GPT-4o Vision
- ğŸ”„ **Two-Step Workflow**: Separate generation from application for manual review
- ğŸ“Š **Context-Aware Generation**: 5-level hierarchical context extraction for accurate descriptions
- ğŸ¯ **Dynamic Confidence Scoring**: Quality-based scores (0.1-1.0) considering validation, warnings, and length
- ğŸ–¼ï¸ **Image Embedding**: JSON includes base64-encoded images for human review
- âœ… **ADA Compliance Validation**: Automatic validation of length, content, and formatting
- ğŸ’¾ **Reusable Alt-Text**: Generate once, apply to multiple document versions
- ğŸ¯ **Position Preservation**: Images remain in exact original positions
- ğŸ“ **Comprehensive Reporting**: Markdown reports with statistics, costs, and error tracking
- âš¡ **Batch Processing**: Process multiple images with progress tracking
- ğŸ›¡ï¸ **Error Resilience**: Continue processing on individual failures
- ğŸ“ **Structured Logging**: JSON logs with correlation IDs for debugging
- ğŸ”„ **Semantic Kernel Integration**: Robust AI orchestration with retry logic and error handling

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11 or higher
- [uv](https://github.com/astral-sh/uv) - Fast Python package manager
- Azure OpenAI account with GPT-4o deployment

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/yourusername/ada-annotator.git
cd ada-annotator
```

2. **Run automated setup** (recommended):
```powershell
# Windows PowerShell
.\scripts\setup.ps1
```

This script will:
- Install uv if not already installed
- Create virtual environment
- Install all dependencies
- Create `.env` file from template
- Verify installation

3. **Configure Azure OpenAI** (edit `.env`):
```bash
AI_SERVICE_TYPE=azure_openai
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

4. **Process your first document:**
```bash
# Using uv with the annotate command (simplest - note: input is positional, not --input)
uv run annotate tests/fixtures/documents/sample.docx --output output.docx --log-level INFO

# Or using the full module path
uv run python -m ada_annotator.cli tests/fixtures/documents/sample.docx --output output.docx --log-level INFO

# Or activate virtual environment first, then use the command directly
# Windows
.\.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate

annotate tests/fixtures/documents/sample.docx --output output.docx --log-level INFO
```

See [SETUP_GUIDE.md](SETUP_GUIDE.md) for detailed setup instructions and troubleshooting.

## ğŸ“– Usage

### Command Line Interface (CLI)

The primary interface offers two workflow options:

#### **Two-Step Workflow (Recommended)**

The two-step workflow separates alt-text generation from document modification, allowing manual review:

```bash
# Step 1: Extract images and generate alt-text (saves to JSON + HTML)
uv run annotate extract document.docx -o alttext.json

# Step 2: Review the HTML file - open in your browser to see images!
# - Open document_alttext.html in any browser
# - See images displayed alongside their alt-text
# - Beautiful, interactive report with metadata
# (JSON file is also created for programmatic access)

# Step 3: Apply reviewed alt-text to document
uv run annotate apply document.docx alttext.json -o annotated.docx
```

**Benefits of Two-Step Workflow:**
- ğŸ’° **Cost Savings**: Generate once, apply to multiple output formats
- ğŸ‘ï¸ **Manual Review**: Beautiful HTML report showing images with their alt-text
- âœï¸ **Editable**: Modify alt-text in JSON before applying
- ğŸ”„ **Reusable**: Apply same alt-text to updated document versions
- ğŸ“Š **Traceable**: Both HTML (human-readable) and JSON (machine-readable) formats

**Extract Command Options:**
```bash
# Basic extraction
uv run annotate extract document.docx

# Specify output JSON path
uv run annotate extract document.docx -o my_alttext.json

# Include external context for better descriptions
uv run annotate extract document.docx -o alttext.json -c course_context.txt

# Limit to first 5 images (for testing)
uv run annotate extract document.docx --max-images 5

# Works with DOCX, PPTX, and PDF
uv run annotate extract presentation.pptx -o alttext.json
```

**Apply Command Options:**
```bash
# Basic application
uv run annotate apply document.docx alttext.json

# Specify output path
uv run annotate apply document.docx alttext.json -o final.docx

# Create backup before applying
uv run annotate apply document.docx alttext.json --backup
```

**JSON Format:**
The intermediate JSON file includes:
- Base64-encoded images (for programmatic access)
- Generated alt-text for each image
- Confidence scores and validation results
- Image metadata (dimensions, position, format)
- Processing statistics and timestamps

**HTML Report:**
A beautiful, interactive HTML file is also generated showing:
- ğŸ–¼ï¸ **Visual Display**: Images shown directly (no base64 decoding needed)
- ğŸ“Š **Statistics Dashboard**: Overview of processing results
- âœ… **Validation Status**: Color-coded badges for each image
- ğŸ“ **Metadata**: Dimensions, file size, confidence scores
- âš ï¸ **Warnings**: Highlighted validation issues
- ğŸ¨ **Modern Design**: Responsive, gradient UI with smooth animations

Simply open the HTML file in any browser to review your images and their alt-text!

#### **Single-Step Workflow (Legacy)**

For backward compatibility, the original single-step workflow is still supported:

```bash
# Process a DOCX file directly (using uv) - INPUT IS POSITIONAL
uv run annotate document.docx --output annotated.docx

# Process a PowerPoint presentation
uv run annotate presentation.pptx --output annotated.pptx

# Use external context file for better descriptions
uv run annotate document.docx \
    --output annotated.docx \
    --context course_syllabus.txt

# Dry-run mode (extract images and preview without generating alt-text)
uv run annotate document.docx --dry-run

# Debug mode (create debug document with images and annotations)
uv run annotate document.docx --debug

# Limit processing to first 5 images (for testing)
uv run annotate document.docx \
    --output annotated.docx \
    --max-images 5

# Enable verbose logging
uv run annotate document.docx \
    --output annotated.docx \
    --log-level DEBUG
```

**Note:** `uv run annotate` automatically uses the project's virtual environment. You can also activate the virtual environment and use `annotate` directly.

### Common Workflows

**1. Two-Step Review Workflow (Recommended):**
```bash
# Extract and generate alt-text
uv run annotate extract lecture_notes.docx -o alttext.json

# Open the HTML file in your browser to review
# lecture_notes_alttext.html shows all images with their alt-text
# Edit JSON file if you need to modify any alt-text

# Apply to original document
uv run annotate apply lecture_notes.docx alttext.json -o final_lecture.docx

# Or apply to different format/version
uv run annotate apply lecture_notes_v2.docx alttext.json -o final_v2.docx
```

**2. Quick Single-Step Processing:**
```bash
# Process sample document with debug logging
uv run annotate tests/fixtures/documents/sample.docx \
    --output output/annotated.docx \
    --log-level DEBUG
```

**3. Batch Processing Multiple Documents:**
```bash
# Extract alt-text for all DOCX files (using PowerShell)
Get-ChildItem *.docx | ForEach-Object {
    uv run annotate extract $_.Name -o "json/$($_.BaseName)_alttext.json"
}

# Review JSON files, then apply
Get-ChildItem json/*.json | ForEach-Object {
    $docName = $_.BaseName -replace '_alttext$','.docx'
    uv run annotate apply $docName $_.FullName -o "output/$docName"
}
```

**4. Educational Content with Context:**
```bash
# Include course context for better descriptions
uv run annotate extract lecture_notes.docx \
    -o alttext.json \
    -c course_context.md \
    --log-level INFO

# Review and apply
uv run annotate apply lecture_notes.docx alttext.json -o annotated_lecture.docx
```

### Output Files

#### Two-Step Workflow Output:
After extraction:
- **JSON File**: `{input_name}_alttext.json` containing:
  - Base64-encoded images for programmatic access
  - AI-generated alt-text for each image
  - Confidence scores (0.1-1.0) based on quality factors
  - Validation results and warnings
  - Image metadata (dimensions, position, format)
  - Processing statistics
- **HTML Report**: `{input_name}_alttext.html` - beautiful interactive report showing:
  - Images displayed directly in the browser
  - Alt-text alongside each image
  - Statistics dashboard with processing metrics
  - Color-coded validation badges
  - Metadata and warnings clearly highlighted
  - Modern, responsive design

After application:
- **Annotated Document**: Original document with alt-text applied
- **JSON Log File**: `logs/ada-annotator.log` with structured logs

#### Single-Step Workflow Output:
After processing:
- **Annotated Document**: Your original document with AI-generated alt-text applied
- **Markdown Report**: `{output_name}_report.md` with:
  - Processing statistics (success rate, duration)
  - List of processed images with alt-text previews
  - Failed images with error messages
  - Token usage and estimated costs
- **JSON Log File**: `logs/ada-annotator.log` with structured processing logs

### Streamlit Web Interface (Future)

A web interface is planned for Phase 2:

1. **Upload Document**: Drag and drop a DOCX file or click to browse
2. **Extract Images**: System automatically extracts all images
3. **Generate Alt-Text**: AI analyzes each image and creates descriptions
4. **Review**: Preview generated alt-text for each image
5. **Download**: Get your annotated document with alt-text applied

## ğŸ—ï¸ Project Structure

```
ada-annotator/
â”œâ”€â”€ src/ada_annotator/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Pydantic settings and configuration
â”‚   â”œâ”€â”€ exceptions.py          # Custom exception hierarchy
â”‚   â”œâ”€â”€ cli.py                 # Command-line interface (Phase 1)
â”‚   â”œâ”€â”€ app.py                 # Streamlit web app (Phase 2 - planned)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ image_metadata.py  # Image extraction results
â”‚   â”‚   â”œâ”€â”€ context_data.py    # Hierarchical context
â”‚   â”‚   â”œâ”€â”€ alt_text_result.py # AI generation results
â”‚   â”‚   â””â”€â”€ processing_result.py # Document processing summary
â”‚   â”‚
â”‚   â”œâ”€â”€ document_processors/   # DOCX & PPTX handling
â”‚   â”‚   â”œâ”€â”€ base_extractor.py  # Abstract extractor base
â”‚   â”‚   â”œâ”€â”€ docx_extractor.py  # DOCX image extraction
â”‚   â”‚   â”œâ”€â”€ pptx_extractor.py  # PPTX image extraction
â”‚   â”‚   â”œâ”€â”€ base_assembler.py  # Abstract assembler base
â”‚   â”‚   â”œâ”€â”€ docx_assembler.py  # DOCX alt-text application
â”‚   â”‚   â””â”€â”€ pptx_assembler.py  # PPTX alt-text application
â”‚   â”‚
â”‚   â”œâ”€â”€ ai_services/           # AI integration
â”‚   â”‚   â””â”€â”€ semantic_kernel_service.py # SK + Azure OpenAI
â”‚   â”‚
â”‚   â”œâ”€â”€ generators/            # Alt-text generation
â”‚   â”‚   â””â”€â”€ alt_text_generator.py # Orchestrator with validation
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Utility modules
â”‚       â”œâ”€â”€ logging.py         # Structured logging (structlog)
â”‚       â”œâ”€â”€ error_handler.py   # Error handling framework
â”‚       â”œâ”€â”€ error_tracker.py   # Error tracking and categorization
â”‚       â”œâ”€â”€ context_extractor.py # 5-level context extraction
â”‚       â”œâ”€â”€ image_utils.py     # Image processing utilities
â”‚       â”œâ”€â”€ retry_handler.py   # Exponential backoff retry logic
â”‚       â””â”€â”€ report_generator.py # Markdown report generation
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                  # Unit tests (271 tests, 100% pass)
â”‚   â”œâ”€â”€ integration/           # Integration tests (planned)
â”‚   â””â”€â”€ fixtures/              # Test documents and data
â”‚       â”œâ”€â”€ documents/         # Sample DOCX/PPTX files
â”‚       â””â”€â”€ context/           # Sample context files
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ requirements.md        # Project requirements
â”‚   â”œâ”€â”€ phase_summaries/       # Phase implementation summaries
â”‚   â””â”€â”€ adr/                   # Architecture Decision Records
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup.ps1              # Automated setup script (Windows)
â”‚
â”œâ”€â”€ .copilot-tracking/         # Implementation tracking (internal)
â”‚   â”œâ”€â”€ plans/                 # Task plans and checklists
â”‚   â”œâ”€â”€ details/               # Detailed specifications
â”‚   â”œâ”€â”€ research/              # Research and references
â”‚   â””â”€â”€ changes/               # Implementation change logs
â”‚
â”œâ”€â”€ pyproject.toml             # Project config (dependencies, tools)
â”œâ”€â”€ .env.example               # Environment variable template
â”œâ”€â”€ SETUP_GUIDE.md             # Detailed setup instructions
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Development

### Running Tests

```bash
# Run all tests with coverage report
pytest --cov=src/ada_annotator --cov-report=term-missing

# Run specific test file
pytest tests/unit/test_alt_text_generator.py -v

# Run tests for a specific module
pytest tests/unit/test_docx_extractor.py tests/unit/test_pptx_extractor.py -v

# Generate HTML coverage report
pytest --cov=src/ada_annotator --cov-report=html
# Open htmlcov/index.html in browser

# Run with verbose output and show print statements
pytest -v -s

# Run only failed tests from last run
pytest --lf
```

**Current Test Status:**
- **271 tests passing (100%)**
- **87% code coverage** (exceeds 80% target)
- All modules tested (unit tests)
- Integration tests planned for Phase 2

### Code Quality

```bash
# Format code with black (79-char line limit)
black src/ tests/ --line-length 79

# Lint with ruff
ruff check src/ tests/

# Fix auto-fixable issues
ruff check src/ tests/ --fix

# Type check with mypy
mypy src/ada_annotator

# Run all quality checks
black src/ tests/ --line-length 79 --check
ruff check src/ tests/
mypy src/ada_annotator
pytest --cov=src/ada_annotator --cov-fail-under=80
```

### Project Standards

All code follows:
- **PEP 8**: Python style guide
- **PEP 257**: Docstring conventions
- **Type hints**: On all function signatures
- **79-character line limit**: For readability
- **4-space indentation**: Standard Python
- **Comprehensive error handling**: All edge cases covered
- **Structured logging**: JSON logs with correlation IDs

See [.github/instructions/python.instructions.md](.github/instructions/python.instructions.md) for full coding standards.

### Using UV Commands

```bash
# Install dependencies
uv pip install -e ".[dev]"

# Add a new package
uv pip install package-name

# Update all dependencies
uv pip install --upgrade -e ".[dev]"

# Sync dependencies from pyproject.toml
uv pip sync
```

## ğŸ“‹ Requirements

See [docs/requirements.md](docs/requirements.md) for detailed project requirements.

### Core Dependencies

- **Document Processing**: python-docx, pypdf, python-pptx, Pillow
- **AI/ML**: semantic-kernel, openai, azure-identity
- **Web Framework**: streamlit
- **Configuration**: python-dotenv, pydantic

## ğŸ—ºï¸ Roadmap

### Phase 1: CLI Implementation âœ… COMPLETE
- [x] Project infrastructure (logging, models, error handling)
- [x] CLI argument parsing and validation
- [x] DOCX image extraction with position metadata
- [x] PPTX image extraction with EMU precision
- [x] 5-level hierarchical context extraction
- [x] Semantic Kernel + Azure OpenAI integration
- [x] Alt-text generation with validation
- [x] DOCX output with position preservation
- [x] PPTX output with property preservation
- [x] Markdown reports and error tracking
- [x] Comprehensive test suite (87% coverage)
- [x] Complete documentation

**Status:** Phase 1 is production-ready with >80% test coverage

### Phase 2: Web Interface (Planned - Week 3-4)
- [ ] Streamlit web application
- [ ] File upload interface
- [ ] Real-time processing progress
- [ ] Manual alt-text review/editing
- [ ] Batch document processing
- [ ] Deploy to Azure App Service

### Phase 3: Enhanced Features (Future)
- [ ] PDF support with OCR integration
- [ ] Multi-language support
- [ ] Custom validation rules
- [ ] Alt-text quality scoring
- [ ] A/B testing for prompt optimization
- [ ] Integration with LMS platforms

### Phase 4: Enterprise Features (Future)
- [ ] Azure Functions deployment
- [ ] Queue-based batch processing
- [ ] User authentication and authorization
- [ ] Document version history
- [ ] Audit logging and compliance reporting
- [ ] RESTful API for integrations

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Microsoft Semantic Kernel team for the excellent AI orchestration framework
- OpenAI/Azure OpenAI for powerful vision capabilities
- python-docx, python-pptx, pypdf maintainers for document processing libraries

## ğŸ“ Support

- ğŸ“§ Email: your.email@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/ada-annotator/issues)
- ğŸ“– Documentation: [Project Docs](https://github.com/yourusername/ada-annotator/docs)

## ğŸ”’ Security

- Never commit `.env` files
- Store API keys securely in environment variables
- Use Azure Key Vault for production deployments
- Follow FERPA guidelines for educational records

---

**Made with â¤ï¸ for accessibility in education**
